{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Relative Positional Key Attention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute attn contribution between relative positional keys and queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1D relpos keys\n",
        "import torch\n",
        "\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "\n",
        "@triton.jit\n",
        "def relpos_key_attn_kernel(\n",
        "    x_ptr,             # (B, S, 1)\n",
        "    output_ptr,        # (B, S, S)\n",
        "    queries_ptr,       # (B, S, DIMS)\n",
        "    relpos_keys_ptr,   # (2 * extent + 1, DIMS)\n",
        "    dseq,              # Sequence length S\n",
        "    extent,\n",
        "    DIMS: tl.constexpr,   # Dimension of keys/queries\n",
        "    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\n",
        "):\n",
        "    batch = tl.program_id(axis=0)\n",
        "    row = tl.program_id(axis=1)\n",
        "    colblock = tl.program_id(axis=2)\n",
        "\n",
        "    # Load positions\n",
        "    block_start = batch * dseq + colblock * BLOCK_SIZE\n",
        "    x_query_ptr = x_ptr + batch * dseq + row\n",
        "    x_key_offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
        "    x_key_ptrs = x_ptr + x_key_offsets\n",
        "    x_key_mask = colblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE) < dseq\n",
        "    x_query = tl.load(x_query_ptr)\n",
        "    x_key = tl.load(x_key_ptrs, mask=x_key_mask)\n",
        "    # Compute relative positions\n",
        "    relpos = x_key - x_query\n",
        "    # Compute relative position key indices\n",
        "    relpos_indices = tl.minimum(tl.maximum(relpos, -extent), extent) + extent\n",
        "    # Load keys and queries\n",
        "    relpos_keys_ptrs = relpos_keys_ptr + (DIMS * relpos_indices[:, None] + tl.arange(0, DIMS)[None, :])\n",
        "    relpos_keys = tl.load(relpos_keys_ptrs)\n",
        "    query_ptrs = queries_ptr + batch * dseq * DIMS + row * DIMS + tl.arange(0, DIMS)[None, :]    \n",
        "    query = tl.load(query_ptrs)\n",
        "    output = tl.sum(relpos_keys * query, axis=1)\n",
        "\n",
        "    out_offsets = batch * dseq * dseq + colblock * BLOCK_SIZE + dseq * row + tl.arange(0, BLOCK_SIZE)\n",
        "    out_mask = colblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE) < dseq\n",
        "    tl.store(output_ptr + out_offsets, output, mask=out_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1D relpos keys\n",
        "import torch\n",
        "\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "\n",
        "@triton.jit\n",
        "def relpos_key_attn_bwd_dout_dkeys_kernel(\n",
        "    x_ptr,                # (B, S, 1)\n",
        "    dout_ptr,             # (B, S, S)\n",
        "    dout_stride0, dout_stride1, dout_stride2,\n",
        "    queries_ptr,          # (B, S, DIMS)\n",
        "    drelpos_keys_ptr,     # (2 * extent + 1, DIMS)\n",
        "    dseq,                 # Sequence length S\n",
        "    extent,\n",
        "    DIMS: tl.constexpr,   # Dimension of keys/queries\n",
        "    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\n",
        "):\n",
        "    batch = tl.program_id(axis=0)\n",
        "    row = tl.program_id(axis=1)\n",
        "    colblock = tl.program_id(axis=2)\n",
        "\n",
        "    # Load positions\n",
        "    block_start = batch * dseq + colblock * BLOCK_SIZE\n",
        "    x_query_ptr = x_ptr + batch * dseq + row\n",
        "    x_key_offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
        "    x_key_ptrs = x_ptr + x_key_offsets\n",
        "    x_key_mask = colblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE) < dseq\n",
        "    x_query = tl.load(x_query_ptr)\n",
        "    x_key = tl.load(x_key_ptrs, mask=x_key_mask)\n",
        "    # Compute relative positions\n",
        "    relpos = x_key - x_query\n",
        "    # Compute relative position key indices\n",
        "    relpos_indices = tl.minimum(tl.maximum(relpos, -extent), extent) + extent\n",
        "    # Load query\n",
        "    query_ptrs = queries_ptr + batch * dseq * DIMS + row * DIMS + tl.arange(0, DIMS)[None, :]    \n",
        "    query = tl.load(query_ptrs)\n",
        "    # Load dout\n",
        "    dout_ptrs = dout_ptr + batch * dout_stride0 + row * dout_stride1  + colblock * BLOCK_SIZE * dout_stride2 + tl.arange(0, BLOCK_SIZE)[:, None] * dout_stride2\n",
        "    dout = tl.load(dout_ptrs)\n",
        "    # Add query to gradient of all relpos keys\n",
        "    drelpos_keys_ptrs = drelpos_keys_ptr + (DIMS * relpos_indices[:, None] + tl.arange(0, DIMS)[None, :])\n",
        "    out_mask = colblock * BLOCK_SIZE * DIMS + DIMS * tl.arange(0, BLOCK_SIZE)[:, None] + tl.arange(0, DIMS)[None, :] < dseq * DIMS\n",
        "    #tl.atomic_add(drelpos_keys_ptrs, dout * query, mask=out_mask)\n",
        "    tl.atomic_add(drelpos_keys_ptrs, dout * query, mask=out_mask)\n",
        "\n",
        "    #out_offsets = batch * dseq * dseq + colblock * BLOCK_SIZE + dseq * row + tl.arange(0, BLOCK_SIZE)[:, None]\n",
        "    #out_mask2 = colblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)[:, None] < dseq\n",
        "    #tl.store(output_ptr + out_offsets, dout)#, mask=out_mask2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[  0],\n",
            "         [ -5],\n",
            "         [  0],\n",
            "         [-13],\n",
            "         [ -5],\n",
            "         [  5],\n",
            "         [100]],\n",
            "\n",
            "        [[  0],\n",
            "         [ -5],\n",
            "         [  0],\n",
            "         [-13],\n",
            "         [  0],\n",
            "         [  5],\n",
            "         [  3]]], device='cuda:0')\n",
            "output2 tensor([[ 2., -2.,  2., -2., -2., -2., -2.],\n",
            "        [-2.,  2., -2., -2.,  2., -2., -2.],\n",
            "        [ 2., -2.,  2., -2., -2., -2., -2.],\n",
            "        [-2., -2., -2.,  2., -2., -2., -2.],\n",
            "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "        [ 2.,  2.,  2.,  2.,  2.,  0.,  0.],\n",
            "        [ 2.,  2.,  2.,  2.,  2.,  2.,  0.]], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "output1 tensor([[ 2., -2.,  2., -2.,  2., -2., -2.],\n",
            "        [-2.,  2., -2., -2., -2., -2., -2.],\n",
            "        [ 2., -2.,  2., -2.,  2., -2., -2.],\n",
            "        [-2., -2., -2.,  2., -2., -2., -2.],\n",
            "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "        [ 2.,  2.,  2.,  2.,  2.,  0.,  2.],\n",
            "        [ 2.,  2.,  2.,  2.,  2.,  0.,  0.]], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "grad tensor([[ 8.,  8., 14., -8.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  2.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 8.,  8., -8., -8.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 8.,  8., -8., -8.]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class RelposKeyAttn(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(\n",
        "        ctx,\n",
        "        # positions\n",
        "        x: torch.Tensor,\n",
        "        # queries (S, dhead)\n",
        "        queries: torch.Tensor,\n",
        "        # relative positional keys embedding (2 * extent + 1, dhead)\n",
        "        relpos_keys: torch.Tensor,\n",
        "        # extent\n",
        "        extent\n",
        "    ):\n",
        "        batch, elements, feats = x.shape\n",
        "        nembed, dhead = relpos_keys.shape\n",
        "        _batch, _elements, _dhead = queries.shape\n",
        "        assert feats == 1\n",
        "        assert batch == _batch\n",
        "        assert elements == _elements\n",
        "        assert dhead == _dhead\n",
        "        assert nembed == 2 * extent + 1\n",
        "        # We need to preallocate the output\n",
        "        output = torch.empty((batch, elements, elements,), device=x.device, dtype=torch.float32)\n",
        "        #output = torch.full((batch, elements, elements,), 1337, dtype=torch.float32).to(x.device)\n",
        "        assert x.is_cuda and output.is_cuda\n",
        "        n_elements = elements\n",
        "        grid = lambda meta: (batch, n_elements, triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
        "        relpos_key_attn_kernel[grid](\n",
        "            x,\n",
        "            output,\n",
        "            queries,\n",
        "            relpos_keys,\n",
        "            n_elements,\n",
        "            extent,\n",
        "            DIMS=dhead,\n",
        "            BLOCK_SIZE=32,\n",
        "            num_warps=1,\n",
        "        )\n",
        "        ctx.save_for_backward(x, queries, relpos_keys)\n",
        "        ctx.extent = extent\n",
        "        return output\n",
        "    \n",
        "    @staticmethod\n",
        "    def backward(ctx, dout):\n",
        "        x, queries, relpos_keys = ctx.saved_tensors\n",
        "        batch, n_elements, feats = x.shape\n",
        "        nembed, dhead = relpos_keys.shape\n",
        "        drelpos_keys = torch.zeros_like(relpos_keys, device=x.device)\n",
        "\n",
        "        grid = lambda meta: (batch, n_elements, triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
        "        relpos_key_attn_bwd_dout_dkeys_kernel[grid](\n",
        "            x,\n",
        "            dout,\n",
        "            dout.stride()[0],\n",
        "            dout.stride()[1],\n",
        "            dout.stride()[2],\n",
        "            queries,\n",
        "            drelpos_keys,\n",
        "            n_elements,\n",
        "            ctx.extent,\n",
        "            DIMS=dhead,\n",
        "            BLOCK_SIZE=32,\n",
        "            num_warps=1,\n",
        "        )\n",
        "\n",
        "        return None, None, drelpos_keys, None\n",
        "\n",
        "relpos_key_attn = RelposKeyAttn.apply\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "positions = torch.tensor([\n",
        "    [[0], [-5], [0], [-13], [-5], [5], [100]],\n",
        "    [[0], [-5], [0], [-13], [0], [5], [3]],\n",
        "]).to('cuda')\n",
        "#positions = torch.zeros((2, 7, 1), dtype=torch.int64).to('cuda')\n",
        "queries = torch.zeros(2, 7, 4).to('cuda')\n",
        "queries[:, :4] = torch.tensor([1.0, 1.0, -1.0, -1.0])\n",
        "queries[:, 5:] = torch.tensor([0.0, 0.0, 2.0, 0])\n",
        "relpos_keys = torch.zeros(11, 4).to('cuda')\n",
        "relpos_keys[:5] = torch.tensor([-0.5, -0.5, 1.0, 0])\n",
        "relpos_keys[5] = torch.tensor([1.0, 1.0, 0, 0])\n",
        "relpos_keys[6:] = torch.tensor([-0.5, -0.5, 0.0, 1.0])\n",
        "\n",
        "print(positions)\n",
        "\n",
        "relpos_keys.requires_grad_(True)\n",
        "#queries.requires_grad_(True)\n",
        "\n",
        "output = relpos_key_attn(positions, queries, relpos_keys, 5)\n",
        "print(\"output2\", output[0])\n",
        "print(\"output1\", output[1])\n",
        "(output * torch.tensor([1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0], device='cuda')).sum().backward()\n",
        "print(\"grad\", relpos_keys.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relpos_key_attn_torch(\n",
        "    # positions\n",
        "    x: torch.Tensor,\n",
        "    # queries (S, dhead)\n",
        "    queries: torch.Tensor,\n",
        "    # relative positional keys embedding (2 * extent + 1, dhead)\n",
        "    relpos_keys: torch.Tensor,\n",
        "    # extent\n",
        "    extent\n",
        "):\n",
        "    extent = torch.tensor(extent).to(x.device)\n",
        "    dbatch, elements, feats = x.shape\n",
        "    nembed, dhead = relpos_keys.shape\n",
        "    assert feats == 1\n",
        "    assert nembed == 2 * extent + 1\n",
        "    assert queries.size(-1) == dhead\n",
        "\n",
        "    # Batch x Seq x Seq x Pos relative positions\n",
        "    relative_positions = x.squeeze(-1).unsqueeze(1) - x.unsqueeze(2).squeeze(-1)\n",
        "\n",
        "    clamped_positions = torch.max(\n",
        "        torch.min(\n",
        "            extent,  # type: ignore\n",
        "            relative_positions.long(),\n",
        "        ),\n",
        "        -extent,  # type: ignore\n",
        "    )\n",
        "    positive_positions = clamped_positions + extent\n",
        "    indices = positive_positions#(positive_positions * self.strides).sum(dim=-1).long()\n",
        "    # Batch x Seq x Seq x d_model\n",
        "    relkeys = relpos_keys[indices]\n",
        "    return torch.einsum(\"bsd,bstd->bst\", queries, relkeys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[30.2208, 29.7816, 29.7816,  ..., 29.7816, 30.6755, 34.9812],\n",
            "        [31.5203, 28.9670, 34.0328,  ..., 32.0844, 33.9999, 30.4027],\n",
            "        [31.6798, 29.2125, 27.1991,  ..., 30.8380, 31.6798, 31.6798],\n",
            "        ...,\n",
            "        [34.9031, 32.8088, 34.4261,  ..., 33.1806, 34.9031, 33.1504],\n",
            "        [28.7967, 30.4605, 29.9418,  ..., 29.9418, 29.7341, 29.6608],\n",
            "        [31.0516, 32.2823, 33.3266,  ..., 33.7131, 31.9300, 31.7409]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "tensor([[30.2208, 29.7816, 29.7816,  ..., 29.7816, 30.6755, 34.9812],\n",
            "        [31.5203, 28.9670, 34.0328,  ..., 32.0844, 33.9999, 30.4027],\n",
            "        [31.6798, 29.2125, 27.1991,  ..., 30.8380, 31.6798, 31.6798],\n",
            "        ...,\n",
            "        [34.9031, 32.8088, 34.4261,  ..., 33.1806, 34.9031, 33.1504],\n",
            "        [28.7967, 30.4605, 29.9418,  ..., 29.9418, 29.7341, 29.6608],\n",
            "        [31.0516, 32.2823, 33.3266,  ..., 33.7132, 31.9300, 31.7409]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "The maximum difference between torch and triton is 1.1444091796875e-05\n",
            "tensor([[15369.8389, 15641.6123, 15405.6602,  ..., 15743.3525, 15375.7197,\n",
            "         15304.5176],\n",
            "        [ 6017.0210,  6007.5396,  5968.9160,  ...,  6041.2236,  5988.4736,\n",
            "          5943.5269],\n",
            "        [ 6938.5537,  6970.3096,  6874.7031,  ...,  6889.3657,  6785.3867,\n",
            "          6925.5200],\n",
            "        ...,\n",
            "        [ 6953.5337,  6958.3691,  6794.3213,  ...,  6859.9512,  6822.6162,\n",
            "          6933.8716],\n",
            "        [ 5989.9297,  6064.0415,  5905.3140,  ...,  5896.3892,  5863.4346,\n",
            "          5986.2554],\n",
            "        [15530.3633, 15822.2334, 15356.9658,  ..., 15304.3818, 15534.9258,\n",
            "         15291.6855]], device='cuda:0')\n",
            "tensor([[15369.8770, 15641.5342, 15405.6816,  ..., 15743.4775, 15375.6719,\n",
            "         15304.5371],\n",
            "        [ 6017.0181,  6007.5376,  5968.9375,  ...,  6041.2476,  5988.4590,\n",
            "          5943.5303],\n",
            "        [ 6938.5435,  6970.3071,  6874.6831,  ...,  6889.3633,  6785.3706,\n",
            "          6925.5195],\n",
            "        ...,\n",
            "        [ 6953.5376,  6958.3633,  6794.3125,  ...,  6859.9590,  6822.5723,\n",
            "          6933.8755],\n",
            "        [ 5989.9312,  6064.0635,  5905.3086,  ...,  5896.3926,  5863.4604,\n",
            "          5986.2588],\n",
            "        [15530.3408, 15822.2949, 15357.0166,  ..., 15304.3223, 15534.7441,\n",
            "         15291.7637]], device='cuda:0')\n",
            "The maximum relative gradient difference between torch and triton is 5.4836273193359375e-06\n"
          ]
        }
      ],
      "source": [
        "dhead = 128\n",
        "size = 80\n",
        "dbatch = 64\n",
        "x = (torch.rand((dbatch, size, 1), device='cuda', dtype=torch.float32) * 10).long()\n",
        "queries = torch.rand((dbatch, size, dhead), device='cuda', dtype=torch.float32)\n",
        "embeddings = torch.rand((2 * 5 + 1, dhead), device='cuda', dtype=torch.float32)\n",
        "embeddings_torch = embeddings.clone()\n",
        "embeddings.requires_grad_(True)\n",
        "embeddings_torch.requires_grad_(True)\n",
        "\n",
        "output_triton = relpos_key_attn(x, queries, embeddings, 5)\n",
        "output_torch = relpos_key_attn_torch(x, queries, embeddings_torch, 5)\n",
        "print(output_torch[1])\n",
        "print(output_triton[1])\n",
        "print(\n",
        "    f'The maximum difference between torch and triton is '\n",
        "    f'{torch.max(torch.abs(output_torch - output_triton))}'\n",
        ")\n",
        "\n",
        "randout = torch.rand((dbatch, size, size), device='cuda', dtype=torch.float32)\n",
        "(output_triton * randout).sum().backward()\n",
        "(output_torch * randout).sum().backward()\n",
        "print(embeddings.grad)\n",
        "print(embeddings_torch.grad)\n",
        "print(\n",
        "    f'The maximum relative gradient difference between torch and triton is '\n",
        "    f'{1 - torch.max(torch.abs(embeddings.grad - embeddings_torch.grad) / (torch.abs(embeddings.grad - embeddings_torch.grad) + 1e-6))}'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now use the above function to compute the element-wise sum of two `torch.tensor` objects and test its correctness:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seems like we're good to go!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benchmark\n",
        "We can now benchmark our custom op on vectors of increasing sizes to get a sense of how it does relative to PyTorch.\n",
        "To make things easier, Triton has a set of built-in utilities that allow us to concisely plot the performance of your custom ops\n",
        "for different problem sizes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "relpos-keyattn-performance:\n",
            "     size    Triton     Torch\n",
            "0     2.0  0.187661  0.020885\n",
            "1     4.0  0.285663  0.019015\n",
            "2     8.0  0.290157  0.018765\n",
            "3    16.0  0.292398  0.018967\n",
            "4    32.0  0.293917  0.019035\n",
            "5    64.0  0.294702  0.019211\n",
            "6   128.0  0.295235  0.019283\n",
            "7   256.0  0.295488  0.019356\n",
            "8   512.0  0.295580  0.019352\n",
            "9  1024.0  0.293330  0.019271\n"
          ]
        }
      ],
      "source": [
        "@triton.testing.perf_report(\n",
        "    triton.testing.Benchmark(\n",
        "        x_names=['size'],  # argument names to use as an x-axis for the plot\n",
        "        x_vals=[\n",
        "            2 ** i for i in range(1, 11, 1)\n",
        "        ],  # different possible values for `x_name`\n",
        "        x_log=True,  # x axis is logarithmic\n",
        "        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n",
        "        line_vals=['triton', 'torch'],  # possible values for `line_arg`\n",
        "        #line_vals=['triton'],#, 'torch'],  # possible values for `line_arg`\n",
        "        line_names=['Triton', 'Torch'],  # label name for the lines\n",
        "        styles=[('blue', '-'), ('green', '-')],  # line styles\n",
        "        ylabel='GB/s',  # label name for the y-axis\n",
        "        plot_name='relpos-keyattn-performance',  # name for the plot. Used also as a file name for saving the plot.\n",
        "        args={'mode': 'backward'},  # values for function arguments not in `x_names` and `y_name`\n",
        "    )\n",
        ")\n",
        "def benchmark(size, provider, mode='backward'):\n",
        "    dhead = 128\n",
        "    dseq = 50\n",
        "    x = (torch.rand((size, dseq, 1), device='cuda', dtype=torch.float32)).long()\n",
        "    queries = torch.rand((size, dseq, dhead), device='cuda', dtype=torch.float32)\n",
        "    embeddings = torch.rand((2 * 5 + 1, dhead), device='cuda', dtype=torch.float32)\n",
        "    dout = .1 * torch.rand((size, dseq, dseq), device='cuda', dtype=torch.float32)\n",
        "\n",
        "    #y = (torch.rand(size, device='cuda', dtype=torch.float32) * 10).long()\n",
        "    if provider == 'torch':\n",
        "        if mode == 'backward':\n",
        "            embeddings.requires_grad_(True)\n",
        "            ms, min_ms, max_ms = triton.testing.do_bench(lambda: relpos_key_attn_torch(x, queries, embeddings, 5).backward(dout, retain_graph=True))\n",
        "        else:\n",
        "            ms, min_ms, max_ms = triton.testing.do_bench(lambda: relpos_key_attn_torch(x, queries, embeddings, 5))\n",
        "    if provider == 'triton':\n",
        "        if  mode == 'backward':\n",
        "            embeddings.requires_grad_(True)\n",
        "            ms, min_ms, max_ms = triton.testing.do_bench(lambda: relpos_key_attn(x, queries, embeddings, 5).backward(dout, retain_graph=True))\n",
        "        else:\n",
        "            ms, min_ms, max_ms = triton.testing.do_bench(lambda: relpos_key_attn(x, queries, embeddings, 5))\n",
        "    gbps = lambda ms: 4 * dhead * size * dseq / ms * 1e-6\n",
        "    return gbps(ms), gbps(max_ms), gbps(min_ms)\n",
        "\n",
        "benchmark.run(print_data=True, show_plots=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
