{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Relative Positional Key Attention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute attn contribution between relative positional keys and queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 5,  6,  7,  8,  9],\n",
            "         [ 4,  5,  6,  7,  8],\n",
            "         [ 3,  4,  5,  6,  7],\n",
            "         [ 2,  3,  4,  5,  6],\n",
            "         [ 1,  2,  3,  4,  5]],\n",
            "\n",
            "        [[ 5, 10, 10, 10, 10],\n",
            "         [ 0,  5,  0,  0,  0],\n",
            "         [ 0, 10,  5,  2,  2],\n",
            "         [ 0, 10,  8,  5,  5],\n",
            "         [ 0, 10,  8,  5,  5]]], device='cuda:0', dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "\n",
        "@triton.jit\n",
        "def _relpos_1d_indices(\n",
        "    pos_ptr,           # (B, S)\n",
        "    indices_out_ptr,   # (B, S, S)\n",
        "    dseq,              # Sequence length S\n",
        "    extent,\n",
        "    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\n",
        "):\n",
        "    batch = tl.program_id(axis=0)\n",
        "    rowblock = tl.program_id(axis=1)\n",
        "    colblock = tl.program_id(axis=2)\n",
        "\n",
        "    # Load positions\n",
        "    query_pos = tl.load(pos_ptr + batch * dseq + rowblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)[:, None])\n",
        "    key_pos   = tl.load(pos_ptr + batch * dseq + colblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)[None, :])\n",
        "    relpos = key_pos - query_pos\n",
        "    relpos_indices = tl.minimum(tl.maximum(relpos, -extent), extent) + extent\n",
        "    out_offsets = batch * dseq * dseq + dseq * (rowblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)[:, None]) + colblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)[None, :]\n",
        "    out_mask = (rowblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)[:, None] < dseq) & (colblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)[None, :] < dseq)\n",
        "    tl.store(indices_out_ptr + out_offsets, relpos_indices, mask=out_mask)\n",
        "\n",
        "def relpos_1d_indices(pos, extent):\n",
        "    dbatch, dseq = pos.shape\n",
        "    indices_out = torch.empty((dbatch, dseq, dseq), device=pos.device, dtype=torch.int32)\n",
        "    grid = lambda meta: (dbatch, triton.cdiv(dseq, meta['BLOCK_SIZE']), triton.cdiv(dseq, meta['BLOCK_SIZE']),)\n",
        "    _relpos_1d_indices[grid](pos, indices_out, dseq, extent, BLOCK_SIZE=64)\n",
        "    return indices_out\n",
        "\n",
        "\n",
        "positions = torch.tensor([\n",
        "    [0, 1, 2, 3, 4],\n",
        "    [-5, 10, 3, 0, 0],\n",
        "]).to('cuda')\n",
        "print(relpos_1d_indices(positions, extent=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@triton.jit\n",
        "def _relpos_key_attn(\n",
        "    relpos_indices_ptr, # (B, S, S)\n",
        "    output_ptr,         # (B, S, S)\n",
        "    queries_ptr,        # (B, S, DIMS)\n",
        "    relpos_keys_ptr,    # (2 * extent + 1, DIMS)\n",
        "    dseq,               # Sequence length S\n",
        "    DIMS: tl.constexpr,   # Dimension of keys/queries\n",
        "    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\n",
        "):\n",
        "    batch = tl.program_id(axis=0)\n",
        "    row = tl.program_id(axis=1)\n",
        "    colblock = tl.program_id(axis=2)\n",
        "\n",
        "    # Load relative position indices\n",
        "    qk_offsets = batch * dseq * dseq + colblock * BLOCK_SIZE + dseq * row + tl.arange(0, BLOCK_SIZE)\n",
        "    relpos_indices = tl.load(relpos_indices_ptr + qk_offsets)\n",
        "    # Load keys and queries\n",
        "    relpos_keys_ptrs = relpos_keys_ptr + (DIMS * relpos_indices[:, None] + tl.arange(0, DIMS)[None, :])\n",
        "    relpos_keys = tl.load(relpos_keys_ptrs)\n",
        "    query_ptrs = queries_ptr + batch * dseq * DIMS + row * DIMS + tl.arange(0, DIMS)[None, :]    \n",
        "    query = tl.load(query_ptrs)\n",
        "    output = tl.sum(relpos_keys * query, axis=1)\n",
        "\n",
        "    out_mask = colblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE) < dseq\n",
        "    tl.store(output_ptr + qk_offsets, output, mask=out_mask)\n",
        "\n",
        "def relpos_key_attn(relpos_indices, queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1D relpos keys\n",
        "import torch\n",
        "\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "\n",
        "@triton.jit\n",
        "def relpos_key_attn_bwd_dout_dkeys_kernel(\n",
        "    x_ptr,                # (B, S, 1)\n",
        "    dout_ptr,             # (B, S, S)\n",
        "    dout_stride0, dout_stride1, dout_stride2,\n",
        "    queries_ptr,          # (B, S, DIMS)\n",
        "    drelpos_keys_ptr,     # (2 * extent + 1, DIMS)\n",
        "    dseq,                 # Sequence length S\n",
        "    extent,\n",
        "    DIMS: tl.constexpr,   # Dimension of keys/queries\n",
        "    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\n",
        "):\n",
        "    batch = tl.program_id(axis=0)\n",
        "    row = tl.program_id(axis=1)\n",
        "    colblock = tl.program_id(axis=2)\n",
        "\n",
        "    # Load positions\n",
        "    block_start = batch * dseq + colblock * BLOCK_SIZE\n",
        "    x_query_ptr = x_ptr + batch * dseq + row\n",
        "    x_key_offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
        "    x_key_ptrs = x_ptr + x_key_offsets\n",
        "    x_key_mask = colblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE) < dseq\n",
        "    x_query = tl.load(x_query_ptr)\n",
        "    x_key = tl.load(x_key_ptrs, mask=x_key_mask)\n",
        "    # Compute relative positions\n",
        "    relpos = x_key - x_query\n",
        "    # Compute relative position key indices\n",
        "    relpos_indices = tl.minimum(tl.maximum(relpos, -extent), extent) + extent\n",
        "    # Load query\n",
        "    query_ptrs = queries_ptr + batch * dseq * DIMS + row * DIMS + tl.arange(0, DIMS)[None, :]    \n",
        "    query = tl.load(query_ptrs)\n",
        "    # Load dout\n",
        "    dout_ptrs = dout_ptr + batch * dout_stride0 + row * dout_stride1  + colblock * BLOCK_SIZE * dout_stride2 + tl.arange(0, BLOCK_SIZE)[:, None] * dout_stride2\n",
        "    dout = tl.load(dout_ptrs)\n",
        "    # Add query to gradient of all relpos keys\n",
        "    drelpos_keys_ptrs = drelpos_keys_ptr + (DIMS * relpos_indices[:, None] + tl.arange(0, DIMS)[None, :])\n",
        "    out_mask = colblock * BLOCK_SIZE * DIMS + DIMS * tl.arange(0, BLOCK_SIZE)[:, None] + tl.arange(0, DIMS)[None, :] < dseq * DIMS\n",
        "    #tl.atomic_add(drelpos_keys_ptrs, dout * query, mask=out_mask)\n",
        "    tl.atomic_add(drelpos_keys_ptrs, dout * query, mask=out_mask)\n",
        "\n",
        "\n",
        "@triton.jit\n",
        "def relpos_key_attn_bwd_dqueries(\n",
        "    x_ptr,             # (B, S, 1)\n",
        "    dqueries_ptr,      # (B, S, DIMS)\n",
        "    relpos_keys_ptr,   # (2 * extent + 1, DIMS)\n",
        "    dseq,              # Sequence length S\n",
        "    extent,\n",
        "    DIMS: tl.constexpr,   # Dimension of keys/queries\n",
        "    BLOCK_SIZE: tl.constexpr,  # Number of elements each program should process\n",
        "):\n",
        "    batch = tl.program_id(axis=0)\n",
        "    row = tl.program_id(axis=1)\n",
        "    colblock = tl.program_id(axis=2)\n",
        "\n",
        "    # Load positions\n",
        "    block_start = batch * dseq + colblock * BLOCK_SIZE\n",
        "    x_query_ptr = x_ptr + batch * dseq + row\n",
        "    x_key_offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
        "    x_key_ptrs = x_ptr + x_key_offsets\n",
        "    x_key_mask = colblock * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE) < dseq\n",
        "    x_query = tl.load(x_query_ptr)\n",
        "    x_key = tl.load(x_key_ptrs, mask=x_key_mask)\n",
        "    # Compute relative positions\n",
        "    relpos = x_key - x_query\n",
        "    # Compute relative position key indices\n",
        "    relpos_indices = tl.minimum(tl.maximum(relpos, -extent), extent) + extent\n",
        "    # Load keys and queries\n",
        "    relpos_keys_ptrs = relpos_keys_ptr + (DIMS * relpos_indices[:, None] + tl.arange(0, DIMS)[None, :])\n",
        "    relpos_keys = tl.load(relpos_keys_ptrs)\n",
        "    dquery = tl.sum(relpos_keys, axis=0)\n",
        "\n",
        "    dquery_ptrs = dqueries_ptr + batch * dseq * DIMS + row * DIMS + tl.arange(0, DIMS)\n",
        "    tl.store(dquery_ptrs, dquery)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[  0],\n",
            "         [ -5],\n",
            "         [  0],\n",
            "         [-13],\n",
            "         [ -5],\n",
            "         [  5],\n",
            "         [100]],\n",
            "\n",
            "        [[  0],\n",
            "         [ -5],\n",
            "         [  0],\n",
            "         [-13],\n",
            "         [  0],\n",
            "         [  5],\n",
            "         [  3]]], device='cuda:0')\n",
            "output2 tensor([[ 2., -2.,  2., -2., -2., -2., -2.],\n",
            "        [-2.,  2., -2., -2.,  2., -2., -2.],\n",
            "        [ 2., -2.,  2., -2., -2., -2., -2.],\n",
            "        [-2., -2., -2.,  2., -2., -2., -2.],\n",
            "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "        [ 2.,  2.,  2.,  2.,  2.,  0.,  0.],\n",
            "        [ 2.,  2.,  2.,  2.,  2.,  2.,  0.]], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "output1 tensor([[ 2., -2.,  2., -2.,  2., -2., -2.],\n",
            "        [-2.,  2., -2., -2., -2., -2., -2.],\n",
            "        [ 2., -2.,  2., -2.,  2., -2., -2.],\n",
            "        [-2., -2., -2.,  2., -2., -2., -2.],\n",
            "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
            "        [ 2.,  2.,  2.,  2.,  2.,  0.,  2.],\n",
            "        [ 2.,  2.,  2.,  2.,  2.,  0.,  0.]], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            "grad tensor([[ 8.,  8., 14., -8.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  2.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 8.,  8., -8., -8.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.],\n",
            "        [ 8.,  8., -8., -8.]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class RelposKeyAttn(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(\n",
        "        ctx,\n",
        "        # positions\n",
        "        x: torch.Tensor,\n",
        "        # queries (S, dhead)\n",
        "        queries: torch.Tensor,\n",
        "        # relative positional keys embedding (2 * extent + 1, dhead)\n",
        "        relpos_keys: torch.Tensor,\n",
        "        # extent\n",
        "        extent\n",
        "    ):\n",
        "        batch, elements, feats = x.shape\n",
        "        nembed, dhead = relpos_keys.shape\n",
        "        _batch, _elements, _dhead = queries.shape\n",
        "        assert feats == 1\n",
        "        assert batch == _batch\n",
        "        assert elements == _elements\n",
        "        assert dhead == _dhead\n",
        "        assert nembed == 2 * extent + 1\n",
        "        # We need to preallocate the output\n",
        "        output = torch.empty((batch, elements, elements,), device=x.device, dtype=torch.float32)\n",
        "        #output = torch.full((batch, elements, elements,), 1337, dtype=torch.float32).to(x.device)\n",
        "        assert x.is_cuda and output.is_cuda\n",
        "        n_elements = elements\n",
        "        grid = lambda meta: (batch, n_elements, triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
        "        relpos_key_attn_kernel[grid](\n",
        "            x,\n",
        "            output,\n",
        "            queries,\n",
        "            relpos_keys,\n",
        "            n_elements,\n",
        "            extent,\n",
        "            DIMS=dhead,\n",
        "            BLOCK_SIZE=32,\n",
        "            num_warps=1,\n",
        "        )\n",
        "        ctx.save_for_backward(x, queries, relpos_keys)\n",
        "        ctx.extent = extent\n",
        "        return output\n",
        "    \n",
        "    @staticmethod\n",
        "    def backward(ctx, dout):\n",
        "        x, queries, relpos_keys = ctx.saved_tensors\n",
        "        batch, n_elements, feats = x.shape\n",
        "        nembed, dhead = relpos_keys.shape\n",
        "        drelpos_keys = torch.zeros_like(relpos_keys, device=x.device)\n",
        "        dqueries = torch.empty_like(queries, device=x.device)\n",
        "\n",
        "        grid = lambda meta: (batch, n_elements, triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
        "        relpos_key_attn_bwd_dout_dkeys_kernel[grid](\n",
        "            x,\n",
        "            dout,\n",
        "            dout.stride()[0],\n",
        "            dout.stride()[1],\n",
        "            dout.stride()[2],\n",
        "            queries,\n",
        "            drelpos_keys,\n",
        "            n_elements,\n",
        "            ctx.extent,\n",
        "            DIMS=dhead,\n",
        "            BLOCK_SIZE=32,\n",
        "            num_warps=1,\n",
        "        )\n",
        "        relpos_key_attn_bwd_dqueries[grid](\n",
        "            x,\n",
        "            dqueries,\n",
        "            relpos_keys,\n",
        "            n_elements,\n",
        "            ctx.extent,\n",
        "            DIMS=dhead,\n",
        "            BLOCK_SIZE=32,\n",
        "            num_warps=1,\n",
        "        )\n",
        "\n",
        "        return None, dqueries, drelpos_keys, None\n",
        "\n",
        "relpos_key_attn = RelposKeyAttn.apply\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "positions = torch.tensor([\n",
        "    [[0], [-5], [0], [-13], [-5], [5], [100]],\n",
        "    [[0], [-5], [0], [-13], [0], [5], [3]],\n",
        "]).to('cuda')\n",
        "#positions = torch.zeros((2, 7, 1), dtype=torch.int64).to('cuda')\n",
        "queries = torch.zeros(2, 7, 4).to('cuda')\n",
        "queries[:, :4] = torch.tensor([1.0, 1.0, -1.0, -1.0])\n",
        "queries[:, 5:] = torch.tensor([0.0, 0.0, 2.0, 0])\n",
        "relpos_keys = torch.zeros(11, 4).to('cuda')\n",
        "relpos_keys[:5] = torch.tensor([-0.5, -0.5, 1.0, 0])\n",
        "relpos_keys[5] = torch.tensor([1.0, 1.0, 0, 0])\n",
        "relpos_keys[6:] = torch.tensor([-0.5, -0.5, 0.0, 1.0])\n",
        "\n",
        "print(positions)\n",
        "\n",
        "relpos_keys.requires_grad_(True)\n",
        "#queries.requires_grad_(True)\n",
        "\n",
        "output = relpos_key_attn(positions, queries, relpos_keys, 5)\n",
        "print(\"output2\", output[0])\n",
        "print(\"output1\", output[1])\n",
        "(output * torch.tensor([1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0], device='cuda')).sum().backward()\n",
        "print(\"grad\", relpos_keys.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relpos_key_attn_torch(\n",
        "    # positions\n",
        "    x: torch.Tensor,\n",
        "    # queries (S, dhead)\n",
        "    queries: torch.Tensor,\n",
        "    # relative positional keys embedding (2 * extent + 1, dhead)\n",
        "    relpos_keys: torch.Tensor,\n",
        "    # extent\n",
        "    extent\n",
        "):\n",
        "    extent = torch.tensor(extent).to(x.device)\n",
        "    dbatch, elements, feats = x.shape\n",
        "    nembed, dhead = relpos_keys.shape\n",
        "    assert feats == 1\n",
        "    assert nembed == 2 * extent + 1\n",
        "    assert queries.size(-1) == dhead\n",
        "\n",
        "    # Batch x Seq x Seq x Pos relative positions\n",
        "    relative_positions = x.squeeze(-1).unsqueeze(1) - x.unsqueeze(2).squeeze(-1)\n",
        "\n",
        "    clamped_positions = torch.max(\n",
        "        torch.min(\n",
        "            extent,  # type: ignore\n",
        "            relative_positions.long(),\n",
        "        ),\n",
        "        -extent,  # type: ignore\n",
        "    )\n",
        "    positive_positions = clamped_positions + extent\n",
        "    indices = positive_positions#(positive_positions * self.strides).sum(dim=-1).long()\n",
        "    # Batch x Seq x Seq x d_model\n",
        "    relkeys = relpos_keys[indices]\n",
        "    return torch.einsum(\"bsd,bstd->bst\", queries, relkeys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[30.2208, 29.7816, 29.7816,  ..., 29.7816, 30.6755, 34.9812],\n",
            "        [31.5203, 28.9670, 34.0328,  ..., 32.0844, 33.9999, 30.4027],\n",
            "        [31.6798, 29.2125, 27.1991,  ..., 30.8380, 31.6798, 31.6798],\n",
            "        ...,\n",
            "        [34.9031, 32.8088, 34.4261,  ..., 33.1806, 34.9031, 33.1504],\n",
            "        [28.7967, 30.4605, 29.9418,  ..., 29.9418, 29.7341, 29.6608],\n",
            "        [31.0516, 32.2823, 33.3266,  ..., 33.7131, 31.9300, 31.7409]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "tensor([[30.2208, 29.7816, 29.7816,  ..., 29.7816, 30.6755, 34.9812],\n",
            "        [31.5203, 28.9670, 34.0328,  ..., 32.0844, 33.9999, 30.4027],\n",
            "        [31.6798, 29.2125, 27.1991,  ..., 30.8380, 31.6798, 31.6798],\n",
            "        ...,\n",
            "        [34.9031, 32.8088, 34.4261,  ..., 33.1806, 34.9031, 33.1504],\n",
            "        [28.7967, 30.4605, 29.9418,  ..., 29.9418, 29.7341, 29.6608],\n",
            "        [31.0516, 32.2823, 33.3266,  ..., 33.7132, 31.9300, 31.7409]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "The maximum difference between torch and triton is 1.1444091796875e-05\n",
            "tensor([[15369.8496, 15641.6025, 15405.6592,  ..., 15743.3652, 15375.7070,\n",
            "         15304.5205],\n",
            "        [ 6017.0200,  6007.5391,  5968.9204,  ...,  6041.2246,  5988.4722,\n",
            "          5943.5293],\n",
            "        [ 6938.5547,  6970.3091,  6874.7007,  ...,  6889.3613,  6785.3823,\n",
            "          6925.5220],\n",
            "        ...,\n",
            "        [ 6953.5322,  6958.3706,  6794.3193,  ...,  6859.9517,  6822.6133,\n",
            "          6933.8667],\n",
            "        [ 5989.9277,  6064.0474,  5905.3071,  ...,  5896.3906,  5863.4341,\n",
            "          5986.2520],\n",
            "        [15530.3652, 15822.2256, 15356.9668,  ..., 15304.3828, 15534.9219,\n",
            "         15291.6924]], device='cuda:0')\n",
            "tensor([[15369.8770, 15641.5342, 15405.6816,  ..., 15743.4775, 15375.6719,\n",
            "         15304.5371],\n",
            "        [ 6017.0181,  6007.5376,  5968.9375,  ...,  6041.2476,  5988.4590,\n",
            "          5943.5303],\n",
            "        [ 6938.5435,  6970.3071,  6874.6831,  ...,  6889.3633,  6785.3706,\n",
            "          6925.5195],\n",
            "        ...,\n",
            "        [ 6953.5376,  6958.3633,  6794.3125,  ...,  6859.9590,  6822.5723,\n",
            "          6933.8755],\n",
            "        [ 5989.9312,  6064.0635,  5905.3086,  ...,  5896.3926,  5863.4604,\n",
            "          5986.2588],\n",
            "        [15530.3408, 15822.2949, 15357.0166,  ..., 15304.3223, 15534.7441,\n",
            "         15291.7637]], device='cuda:0')\n",
            "The maximum relative keys gradient difference between torch and triton is 5.602836608886719e-06\n",
            "tensor([[[16.1472, 18.2146, 14.4540,  ..., 13.3703, 22.8102, 12.4345],\n",
            "         [18.5584, 19.5119, 14.4426,  ..., 13.3196, 22.7840, 13.8322],\n",
            "         [20.8407, 20.1477, 14.5432,  ..., 13.0879, 28.4168, 10.4716],\n",
            "         ...,\n",
            "         [19.7172, 18.5967, 13.3041,  ..., 14.0723, 23.4821, 14.1946],\n",
            "         [21.2516, 20.3745, 14.0467,  ..., 15.6084, 22.9853, 13.8933],\n",
            "         [23.0730, 21.9032, 14.1100,  ..., 15.4395, 23.0628, 15.8742]],\n",
            "\n",
            "        [[25.2477, 22.3513, 12.3606,  ..., 17.0456, 21.0513, 14.3851],\n",
            "         [20.6847, 21.3559, 13.1836,  ..., 14.5229, 24.5412, 13.8001],\n",
            "         [20.9539, 20.6511, 14.3043,  ..., 13.2094, 26.9895, 12.2042],\n",
            "         ...,\n",
            "         [20.9274, 21.7750, 13.3794,  ..., 13.0031, 25.2947, 13.7226],\n",
            "         [21.4844, 20.0285, 13.3377,  ..., 16.3248, 21.7309, 15.0348],\n",
            "         [20.0154, 18.9841, 17.2610,  ..., 15.5637, 20.7464, 14.0820]],\n",
            "\n",
            "        [[23.8309, 22.1769, 10.6545,  ..., 16.3677, 23.0899, 12.5414],\n",
            "         [18.9361, 20.7658, 13.1973,  ..., 12.5512, 25.8968, 12.0829],\n",
            "         [20.5204, 20.9539, 13.5476,  ..., 15.5662, 21.7946, 15.2477],\n",
            "         ...,\n",
            "         [20.5204, 20.9539, 13.5476,  ..., 15.5662, 21.7946, 15.2477],\n",
            "         [19.0472, 19.5784, 14.3890,  ..., 14.6314, 22.8853, 13.4012],\n",
            "         [20.4165, 20.3864, 14.5827,  ..., 13.4237, 22.9869, 15.0009]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[23.4118, 22.0213, 11.5383,  ..., 17.2701, 22.6477, 13.6053],\n",
            "         [22.3186, 21.0177, 13.3158,  ..., 16.1431, 22.3071, 12.0195],\n",
            "         [22.2362, 22.1421, 14.0422,  ..., 12.9089, 26.6921, 12.3837],\n",
            "         ...,\n",
            "         [22.3186, 21.0177, 13.3158,  ..., 16.1431, 22.3071, 12.0195],\n",
            "         [22.3186, 21.0177, 13.3158,  ..., 16.1431, 22.3071, 12.0195],\n",
            "         [20.0936, 19.3836, 12.2304,  ..., 15.9560, 21.7646, 12.9385]],\n",
            "\n",
            "        [[19.3115, 19.1162, 17.4227,  ..., 15.1838, 22.6848, 12.3156],\n",
            "         [19.1470, 18.9082, 13.7513,  ..., 14.2164, 24.9007, 14.1632],\n",
            "         [19.1470, 18.9082, 13.7513,  ..., 14.2164, 24.9007, 14.1632],\n",
            "         ...,\n",
            "         [19.3115, 19.1162, 17.4227,  ..., 15.1838, 22.6848, 12.3156],\n",
            "         [20.3475, 20.9650, 16.2920,  ..., 13.2142, 23.3648, 13.4107],\n",
            "         [23.6292, 21.8043, 13.7494,  ..., 16.8728, 21.3774, 14.3565]],\n",
            "\n",
            "        [[18.8482, 19.6419, 12.1060,  ..., 13.2175, 25.0865, 12.4876],\n",
            "         [18.8672, 20.6680, 14.0965,  ..., 13.4419, 23.3868, 12.4028],\n",
            "         [20.4981, 19.4746, 16.3946,  ..., 14.6332, 23.5339, 15.3239],\n",
            "         ...,\n",
            "         [18.8482, 19.6419, 12.1060,  ..., 13.2175, 25.0865, 12.4876],\n",
            "         [21.5757, 20.5565, 14.5671,  ..., 15.4042, 21.4088, 15.9154],\n",
            "         [20.4981, 19.4746, 16.3946,  ..., 14.6332, 23.5339, 15.3239]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[17.0013, 20.9353, 21.5734,  ..., 18.8571, 20.4532, 18.9303],\n",
            "         [20.7166, 23.1144, 21.5726,  ..., 23.4891, 17.8716, 21.5279],\n",
            "         [21.3034, 22.5475, 22.0060,  ..., 17.8213, 29.0707, 16.5948],\n",
            "         ...,\n",
            "         [20.9785, 23.2940, 17.5081,  ..., 22.5069, 16.0527, 22.8125],\n",
            "         [20.9923, 20.5765, 14.5049,  ..., 21.8214, 15.7443, 18.3623],\n",
            "         [26.6217, 24.5597, 13.0893,  ..., 24.7585, 15.3073, 17.3335]],\n",
            "\n",
            "        [[31.9003, 29.2694, 13.8792,  ..., 27.3585, 17.9302, 21.6000],\n",
            "         [15.6621, 19.1215, 17.7087,  ..., 17.3479, 17.1642, 18.4455],\n",
            "         [23.4030, 27.0907, 22.6470,  ..., 18.7489, 27.7146, 19.8000],\n",
            "         ...,\n",
            "         [19.2303, 22.6716, 20.2853,  ..., 19.0238, 23.7761, 19.6456],\n",
            "         [25.0162, 23.3443, 17.5924,  ..., 24.1402, 18.7831, 24.3474],\n",
            "         [17.8687, 19.5663, 21.0425,  ..., 21.4458, 14.4775, 21.6875]],\n",
            "\n",
            "        [[28.2290, 24.6068, 14.7216,  ..., 26.3559, 15.6231, 20.3653],\n",
            "         [17.1985, 21.2316, 16.9262,  ..., 14.7615, 22.8270, 14.9821],\n",
            "         [18.9973, 22.4168, 16.6159,  ..., 20.8199, 14.5296, 23.6957],\n",
            "         ...,\n",
            "         [23.0738, 25.6761, 20.0445,  ..., 23.3142, 15.5835, 26.9023],\n",
            "         [17.2422, 22.0232, 18.3708,  ..., 20.2991, 14.5817, 19.1145],\n",
            "         [19.8505, 19.7684, 21.7894,  ..., 18.7405, 18.6644, 22.0093]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[27.7251, 24.3887, 12.5780,  ..., 24.9708, 13.2563, 19.7106],\n",
            "         [27.5494, 25.1098, 15.3542,  ..., 27.1088, 16.4958, 19.4846],\n",
            "         [21.6457, 22.3049, 19.4142,  ..., 16.7272, 25.9367, 15.4353],\n",
            "         ...,\n",
            "         [25.3067, 23.4422, 14.6554,  ..., 24.1417, 17.1663, 18.9912],\n",
            "         [25.2675, 22.9307, 13.1194,  ..., 23.9984, 15.3261, 18.3637],\n",
            "         [23.5925, 25.0719, 13.9629,  ..., 24.9864, 16.1038, 18.7425]],\n",
            "\n",
            "        [[20.1041, 22.6179, 24.0827,  ..., 20.6989, 22.0684, 19.5410],\n",
            "         [22.1208, 21.9812, 18.8183,  ..., 18.2925, 28.3144, 19.0061],\n",
            "         [21.5733, 21.0183, 20.0049,  ..., 19.1190, 25.9409, 20.5601],\n",
            "         ...,\n",
            "         [20.6460, 23.0456, 26.3205,  ..., 21.8128, 22.3834, 19.1366],\n",
            "         [19.0355, 20.7047, 19.8700,  ..., 16.1451, 22.7052, 15.9183],\n",
            "         [25.5316, 23.2321, 17.3525,  ..., 24.6016, 15.3318, 19.5817]],\n",
            "\n",
            "        [[15.0869, 19.2412, 18.0273,  ..., 17.0899, 19.5908, 19.6872],\n",
            "         [20.5677, 24.7828, 20.0911,  ..., 18.8207, 26.4593, 16.4821],\n",
            "         [17.2586, 19.1013, 20.8338,  ..., 18.6218, 19.0836, 21.2327],\n",
            "         ...,\n",
            "         [16.8020, 21.1936, 18.0243,  ..., 17.3299, 20.8627, 20.1219],\n",
            "         [27.2645, 27.4149, 23.4410,  ..., 24.8628, 17.8223, 27.4193],\n",
            "         [15.6791, 17.3074, 21.1061,  ..., 18.0542, 18.2028, 20.7760]]],\n",
            "       device='cuda:0')\n",
            "The maximum relative queries gradient difference between torch and triton is 5.960464477539063e-08\n"
          ]
        }
      ],
      "source": [
        "dhead = 128\n",
        "size = 80\n",
        "dbatch = 64\n",
        "\n",
        "x = (torch.rand((dbatch, size, 1), device='cuda', dtype=torch.float32) * 10).long()\n",
        "\n",
        "queries = torch.rand((dbatch, size, dhead), device='cuda', dtype=torch.float32)\n",
        "queries_torch = queries.clone()\n",
        "queries.requires_grad_(True)\n",
        "queries_torch.requires_grad_(True)\n",
        "\n",
        "embeddings = torch.rand((2 * 5 + 1, dhead), device='cuda', dtype=torch.float32)\n",
        "embeddings_torch = embeddings.clone()\n",
        "embeddings.requires_grad_(True)\n",
        "embeddings_torch.requires_grad_(True)\n",
        "\n",
        "output_triton = relpos_key_attn(x, queries, embeddings, 5)\n",
        "output_torch = relpos_key_attn_torch(x, queries_torch, embeddings_torch, 5)\n",
        "print(output_torch[1])\n",
        "print(output_triton[1])\n",
        "print(\n",
        "    f'The maximum difference between torch and triton is '\n",
        "    f'{torch.max(torch.abs(output_torch - output_triton))}'\n",
        ")\n",
        "\n",
        "randout = torch.rand((dbatch, size, size), device='cuda', dtype=torch.float32)\n",
        "(output_triton * randout).sum().backward()\n",
        "(output_torch * randout).sum().backward()\n",
        "print(embeddings.grad)\n",
        "print(embeddings_torch.grad)\n",
        "print(\n",
        "    f'The maximum relative keys gradient difference between torch and triton is '\n",
        "    f'{1 - torch.max(torch.abs(embeddings.grad - embeddings_torch.grad) / (torch.abs(embeddings.grad - embeddings_torch.grad) + 1e-6))}'\n",
        ")\n",
        "print(queries.grad)\n",
        "print(queries_torch.grad)\n",
        "print(\n",
        "    f'The maximum relative queries gradient difference between torch and triton is '\n",
        "    f'{1 - torch.max(torch.abs(queries.grad - queries_torch.grad) / (torch.abs(queries.grad - queries_torch.grad) + 1e-6))}'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now use the above function to compute the element-wise sum of two `torch.tensor` objects and test its correctness:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seems like we're good to go!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benchmark\n",
        "We can now benchmark our custom op on vectors of increasing sizes to get a sense of how it does relative to PyTorch.\n",
        "To make things easier, Triton has a set of built-in utilities that allow us to concisely plot the performance of your custom ops\n",
        "for different problem sizes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "relpos-keyattn-performance:\n",
            "     size    Triton     Torch\n",
            "0     2.0  0.182690  0.020395\n",
            "1     4.0  0.281084  0.018492\n",
            "2     8.0  0.284647  0.017606\n",
            "3    16.0  0.287906  0.018751\n",
            "4    32.0  0.289645  0.019100\n",
            "5    64.0  0.290518  0.019096\n",
            "6   128.0  0.291017  0.019152\n",
            "7   256.0  0.291232  0.019182\n",
            "8   512.0  0.291320  0.019238\n",
            "9  1024.0  0.291409  0.019243\n"
          ]
        }
      ],
      "source": [
        "@triton.testing.perf_report(\n",
        "    triton.testing.Benchmark(\n",
        "        x_names=['size'],  # argument names to use as an x-axis for the plot\n",
        "        x_vals=[\n",
        "            2 ** i for i in range(1, 11, 1)\n",
        "        ],  # different possible values for `x_name`\n",
        "        x_log=True,  # x axis is logarithmic\n",
        "        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n",
        "        line_vals=['triton', 'torch'],  # possible values for `line_arg`\n",
        "        #line_vals=['triton'],#, 'torch'],  # possible values for `line_arg`\n",
        "        line_names=['Triton', 'Torch'],  # label name for the lines\n",
        "        styles=[('blue', '-'), ('green', '-')],  # line styles\n",
        "        ylabel='GB/s',  # label name for the y-axis\n",
        "        plot_name='relpos-keyattn-performance',  # name for the plot. Used also as a file name for saving the plot.\n",
        "        args={'mode': 'backward'},  # values for function arguments not in `x_names` and `y_name`\n",
        "    )\n",
        ")\n",
        "def benchmark(size, provider, mode='backward'):\n",
        "    dhead = 128\n",
        "    dseq = 50\n",
        "    x = (torch.rand((size, dseq, 1), device='cuda', dtype=torch.float32)).long()\n",
        "    queries = torch.rand((size, dseq, dhead), device='cuda', dtype=torch.float32)\n",
        "    embeddings = torch.rand((2 * 5 + 1, dhead), device='cuda', dtype=torch.float32)\n",
        "    dout = .1 * torch.rand((size, dseq, dseq), device='cuda', dtype=torch.float32)\n",
        "\n",
        "    #y = (torch.rand(size, device='cuda', dtype=torch.float32) * 10).long()\n",
        "    if provider == 'torch':\n",
        "        if mode == 'backward':\n",
        "            embeddings.requires_grad_(True)\n",
        "            queries.requires_grad_(True)\n",
        "            ms, min_ms, max_ms = triton.testing.do_bench(lambda: relpos_key_attn_torch(x, queries, embeddings, 5).backward(dout, retain_graph=True))\n",
        "        else:\n",
        "            ms, min_ms, max_ms = triton.testing.do_bench(lambda: relpos_key_attn_torch(x, queries, embeddings, 5))\n",
        "    if provider == 'triton':\n",
        "        if  mode == 'backward':\n",
        "            embeddings.requires_grad_(True)\n",
        "            queries.requires_grad_(True)\n",
        "            ms, min_ms, max_ms = triton.testing.do_bench(lambda: relpos_key_attn(x, queries, embeddings, 5).backward(dout, retain_graph=True))\n",
        "        else:\n",
        "            ms, min_ms, max_ms = triton.testing.do_bench(lambda: relpos_key_attn(x, queries, embeddings, 5))\n",
        "    gbps = lambda ms: 4 * dhead * size * dseq / ms * 1e-6\n",
        "    return gbps(ms), gbps(max_ms), gbps(min_ms)\n",
        "\n",
        "benchmark.run(print_data=True, show_plots=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
